{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier Ice Thickness Change Analysis\n",
    "## Sikkim, Bhutan, and Arunachal Pradesh (High Mountain Asia)\n",
    "\n",
    "This notebook analyzes glacier surface elevation changes using:\n",
    "- **TanDEM-X DEM Change Maps (DCM)** from DLR - 30m resolution pre-calculated height change values\n",
    "- **RGI 7.0 Glacier Outlines** - Randolph Glacier Inventory polygons for the study region\n",
    "\n",
    "### Methodology: DEM Differencing\n",
    "The DCM products already contain the difference between two TanDEM-X acquisitions, representing surface elevation change (\u0394h) in meters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import zipfile\n",
    "import glob\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Geospatial libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from shapely.geometry import box, mapping\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"Rasterio version: {rasterio.__version__}\")\n",
    "print(f\"GeoPandas version: {gpd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "# Define paths relative to the project root\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "\n",
    "# Data directories\n",
    "DCM_ZIP_DIR = PROJECT_ROOT / \"DCM\"                    # Directory with zipped DCM tiles\n",
    "DCM_EXTRACTED_DIR = PROJECT_ROOT / \"DCM_extracted\"    # Where to extract TIF files\n",
    "RGI_DIR = PROJECT_ROOT / \"RGI_Data\"\n",
    "\n",
    "# Input files\n",
    "GLACIER_SHAPEFILE = RGI_DIR / \"sikkim_bhutan_arunachal_clean.shp\"\n",
    "\n",
    "# Output directory for results\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"results\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Analysis parameters\n",
    "NODATA_VALUE = -32767           # TanDEM-X NoData value\n",
    "MIN_VALID_CHANGE = -150         # Minimum realistic elevation change (m) - removes noise\n",
    "MAX_VALID_CHANGE = 100          # Maximum realistic elevation change (m) - removes noise\n",
    "PIXEL_RESOLUTION = 30           # DCM resolution in meters\n",
    "\n",
    "# Time period (TanDEM-X baseline is ~2011-2014, change maps compare to later acquisitions)\n",
    "# The \"LAST1622\" in filenames suggests data from 2016-2022\n",
    "TIME_PERIOD_YEARS = 8           # Approximate time span for rate calculation\n",
    "\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"DCM Directory: {DCM_ZIP_DIR}\")\n",
    "print(f\"Glacier Shapefile: {GLACIER_SHAPEFILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Extract DCM TIF Files from ZIP Archives\n",
    "The DLR DCM data comes as ZIP files. We need to extract only the TIF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dcm_tifs(zip_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Extract TIF files from TanDEM-X DCM ZIP archives.\n",
    "    \n",
    "    The ZIP structure is: archive.zip/FOLDER/DCM/filename.tif\n",
    "    We extract only the .tif files to a flat directory.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    zip_dir : Path\n",
    "        Directory containing the ZIP files\n",
    "    output_dir : Path\n",
    "        Directory to extract TIF files to\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list : Paths to extracted TIF files\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    zip_files = list(Path(zip_dir).glob(\"*.zip\"))\n",
    "    extracted_tifs = []\n",
    "    \n",
    "    print(f\"Found {len(zip_files)} ZIP archives to process...\")\n",
    "    \n",
    "    for i, zip_path in enumerate(zip_files, 1):\n",
    "        try:\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "                # Find TIF files in the archive (they're in the DCM subfolder)\n",
    "                tif_files = [f for f in zf.namelist() \n",
    "                            if f.endswith('.tif') and '/DCM/' in f]\n",
    "                \n",
    "                for tif_name in tif_files:\n",
    "                    # Extract just the filename\n",
    "                    base_name = os.path.basename(tif_name)\n",
    "                    output_path = output_dir / base_name\n",
    "                    \n",
    "                    # Skip if already extracted\n",
    "                    if output_path.exists():\n",
    "                        extracted_tifs.append(output_path)\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract the file\n",
    "                    with zf.open(tif_name) as source:\n",
    "                        with open(output_path, 'wb') as target:\n",
    "                            target.write(source.read())\n",
    "                    \n",
    "                    extracted_tifs.append(output_path)\n",
    "                    \n",
    "            if i % 10 == 0:\n",
    "                print(f\"  Processed {i}/{len(zip_files)} archives...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Failed to process {zip_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"Extraction complete! {len(extracted_tifs)} TIF files ready.\")\n",
    "    return extracted_tifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all TIF files\n",
    "tif_files = extract_dcm_tifs(DCM_ZIP_DIR, DCM_EXTRACTED_DIR)\n",
    "\n",
    "# Display first few files\n",
    "print(\"\\nExtracted TIF files:\")\n",
    "for f in sorted(tif_files)[:5]:\n",
    "    print(f\"  {f.name}\")\n",
    "print(f\"  ... and {len(tif_files)-5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Load Glacier Outlines (RGI 7.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the glacier shapefile\n",
    "glaciers_gdf = gpd.read_file(GLACIER_SHAPEFILE)\n",
    "\n",
    "# Standardize column names to lowercase for consistency\n",
    "glaciers_gdf.columns = [col.lower() for col in glaciers_gdf.columns]\n",
    "\n",
    "print(f\"Loaded {len(glaciers_gdf)} glaciers from RGI shapefile\")\n",
    "print(f\"CRS: {glaciers_gdf.crs}\")\n",
    "print(f\"\\nBounding Box:\")\n",
    "print(f\"  Longitude: {glaciers_gdf.total_bounds[0]:.2f}\u00b0 to {glaciers_gdf.total_bounds[2]:.2f}\u00b0\")\n",
    "print(f\"  Latitude: {glaciers_gdf.total_bounds[1]:.2f}\u00b0 to {glaciers_gdf.total_bounds[3]:.2f}\u00b0\")\n",
    "print(f\"\\nTotal glacier area: {glaciers_gdf['area_km2'].sum():.2f} km\u00b2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display available columns\n",
    "print(\"Available attributes:\")\n",
    "print(glaciers_gdf.columns.tolist())\n",
    "\n",
    "print(\"\\nSample of glacier data:\")\n",
    "display_cols = ['rgi_id', 'glac_name', 'cenlon', 'cenlat', 'area_km2']\n",
    "display_cols = [c for c in display_cols if c in glaciers_gdf.columns]\n",
    "glaciers_gdf[display_cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the glacier outlines to verify the study region\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Plot glaciers colored by longitude (shows spatial distribution)\n",
    "glaciers_gdf.plot(\n",
    "    ax=ax,\n",
    "    column='cenlon',\n",
    "    cmap='viridis',\n",
    "    legend=True,\n",
    "    legend_kwds={'label': 'Longitude (\u00b0E)', 'shrink': 0.6}\n",
    ")\n",
    "\n",
    "# Add region labels\n",
    "ax.annotate('SIKKIM', xy=(88.5, 27.8), fontsize=12, fontweight='bold', color='darkred')\n",
    "ax.annotate('BHUTAN', xy=(89.5, 27.5), fontsize=12, fontweight='bold', color='darkred')\n",
    "ax.annotate('ARUNACHAL', xy=(92.5, 28.0), fontsize=12, fontweight='bold', color='darkred')\n",
    "\n",
    "ax.set_title('RGI 7.0 Glacier Outlines: Sikkim, Bhutan, Arunachal Pradesh', fontsize=14)\n",
    "ax.set_xlabel('Longitude (\u00b0E)')\n",
    "ax.set_ylabel('Latitude (\u00b0N)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'glacier_outlines_map.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMap saved to: {OUTPUT_DIR / 'glacier_outlines_map.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Inspect a Sample DCM Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open one TIF to understand its structure\n",
    "sample_tif = sorted(tif_files)[0]\n",
    "\n",
    "with rasterio.open(sample_tif) as src:\n",
    "    print(f\"Sample Raster: {sample_tif.name}\")\n",
    "    print(f\"=\"*60)\n",
    "    print(f\"CRS: {src.crs}\")\n",
    "    print(f\"Resolution: {src.res[0]:.6f}\u00b0 x {src.res[1]:.6f}\u00b0 (~{src.res[0]*111000:.1f}m)\")\n",
    "    print(f\"Dimensions: {src.width} x {src.height} pixels\")\n",
    "    print(f\"Bounds: {src.bounds}\")\n",
    "    print(f\"Data type: {src.dtypes[0]}\")\n",
    "    print(f\"NoData value: {src.nodata}\")\n",
    "    \n",
    "    # Read a sample to check value range\n",
    "    data = src.read(1)\n",
    "    valid_mask = data != src.nodata\n",
    "    \n",
    "    print(f\"\\nValue Statistics (excluding NoData):\")\n",
    "    print(f\"  Min: {data[valid_mask].min():.2f} m\")\n",
    "    print(f\"  Max: {data[valid_mask].max():.2f} m\")\n",
    "    print(f\"  Mean: {data[valid_mask].mean():.2f} m\")\n",
    "    print(f\"  Valid pixels: {valid_mask.sum():,} ({100*valid_mask.sum()/data.size:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Processing Function\n",
    "\n",
    "This is the core function that:\n",
    "1. Opens a DCM TIF file\n",
    "2. Clips it to the glacier boundaries\n",
    "3. Filters invalid/noisy pixels\n",
    "4. Returns meaningful statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_glacier_change(tif_path, glacier_gdf, \n",
    "                           nodata=NODATA_VALUE,\n",
    "                           min_change=MIN_VALID_CHANGE, \n",
    "                           max_change=MAX_VALID_CHANGE):\n",
    "    \"\"\"\n",
    "    Process a single DCM TIF file to extract glacier elevation changes.\n",
    "    \n",
    "    This function:\n",
    "    1. Opens the raster and reprojects glaciers to match if needed\n",
    "    2. Clips the raster to glacier boundaries using rasterio.mask\n",
    "    3. Filters out invalid pixels (NoData and outliers)\n",
    "    4. Calculates statistics for the valid glacier pixels\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tif_path : str or Path\n",
    "        Path to the DCM GeoTIFF file\n",
    "    glacier_gdf : GeoDataFrame\n",
    "        Glacier outlines (will be reprojected if CRS doesn't match)\n",
    "    nodata : float\n",
    "        NoData value to exclude (default: -32767)\n",
    "    min_change : float\n",
    "        Minimum valid elevation change in meters (removes radar penetration noise)\n",
    "    max_change : float\n",
    "        Maximum valid elevation change in meters (removes acquisition artifacts)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing:\n",
    "        - tile_name: Name of the processed tile\n",
    "        - mean_change: Mean elevation change (m)\n",
    "        - std_change: Standard deviation of change (m)\n",
    "        - median_change: Median elevation change (m)\n",
    "        - pixel_count: Number of valid glacier pixels\n",
    "        - min_change: Minimum change value (m)\n",
    "        - max_change: Maximum change value (m)\n",
    "        - all_values: Array of all valid pixel values (for histograms)\n",
    "    \n",
    "    Returns None if the tile contains no glacier pixels.\n",
    "    \"\"\"\n",
    "    tif_path = Path(tif_path)\n",
    "    \n",
    "    try:\n",
    "        with rasterio.open(tif_path) as src:\n",
    "            raster_crs = src.crs\n",
    "            raster_bounds = src.bounds\n",
    "            \n",
    "            # Create a bounding box for the raster to filter glaciers\n",
    "            raster_bbox = box(raster_bounds.left, raster_bounds.bottom,\n",
    "                             raster_bounds.right, raster_bounds.top)\n",
    "            \n",
    "            # Reproject glaciers to match raster CRS if needed\n",
    "            if glacier_gdf.crs != raster_crs:\n",
    "                glaciers_reproj = glacier_gdf.to_crs(raster_crs)\n",
    "            else:\n",
    "                glaciers_reproj = glacier_gdf\n",
    "            \n",
    "            # Filter to only glaciers that intersect this tile\n",
    "            # This significantly speeds up processing\n",
    "            glaciers_in_tile = glaciers_reproj[glaciers_reproj.intersects(raster_bbox)]\n",
    "            \n",
    "            if len(glaciers_in_tile) == 0:\n",
    "                # No glaciers in this tile - skip gracefully\n",
    "                return None\n",
    "            \n",
    "            # Get the geometries for masking\n",
    "            shapes = [mapping(geom) for geom in glaciers_in_tile.geometry]\n",
    "            \n",
    "            # Clip raster to glacier boundaries\n",
    "            # crop=True reduces output to the extent of the shapes\n",
    "            # all_touched=True includes pixels that touch the boundary\n",
    "            try:\n",
    "                out_image, out_transform = mask(\n",
    "                    src, \n",
    "                    shapes, \n",
    "                    crop=True, \n",
    "                    all_touched=True,\n",
    "                    nodata=nodata\n",
    "                )\n",
    "            except ValueError:\n",
    "                # Shapes don't overlap with raster\n",
    "                return None\n",
    "            \n",
    "            # Flatten the array (we only have 1 band)\n",
    "            glacier_pixels = out_image[0].flatten()\n",
    "            \n",
    "            # === FILTERING ===\n",
    "            # Step 1: Remove NoData values\n",
    "            # NoData in TanDEM-X DCM is typically -32767\n",
    "            valid_mask = glacier_pixels != nodata\n",
    "            \n",
    "            # Step 2: Remove physically unrealistic values\n",
    "            # Large positive values (>100m) indicate acquisition artifacts\n",
    "            # Large negative values (<-150m) can be radar penetration noise in snow/ice\n",
    "            # or phase unwrapping errors\n",
    "            valid_mask &= glacier_pixels >= min_change\n",
    "            valid_mask &= glacier_pixels <= max_change\n",
    "            \n",
    "            valid_pixels = glacier_pixels[valid_mask]\n",
    "            \n",
    "            if len(valid_pixels) == 0:\n",
    "                return None\n",
    "            \n",
    "            # Calculate statistics\n",
    "            return {\n",
    "                'tile_name': tif_path.stem,\n",
    "                'glaciers_in_tile': len(glaciers_in_tile),\n",
    "                'mean_change': float(np.mean(valid_pixels)),\n",
    "                'std_change': float(np.std(valid_pixels)),\n",
    "                'median_change': float(np.median(valid_pixels)),\n",
    "                'pixel_count': int(len(valid_pixels)),\n",
    "                'min_change': float(np.min(valid_pixels)),\n",
    "                'max_change': float(np.max(valid_pixels)),\n",
    "                'all_values': valid_pixels  # Keep for histogram\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing {tif_path.name}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function on one tile\n",
    "print(\"Testing processing function on a single tile...\")\n",
    "test_result = process_glacier_change(sample_tif, glaciers_gdf)\n",
    "\n",
    "if test_result:\n",
    "    print(f\"\\nTest Results for: {test_result['tile_name']}\")\n",
    "    print(f\"  Glaciers in tile: {test_result['glaciers_in_tile']}\")\n",
    "    print(f\"  Valid pixels: {test_result['pixel_count']:,}\")\n",
    "    print(f\"  Mean change: {test_result['mean_change']:.2f} m\")\n",
    "    print(f\"  Median change: {test_result['median_change']:.2f} m\")\n",
    "    print(f\"  Std dev: {test_result['std_change']:.2f} m\")\n",
    "    print(f\"  Range: [{test_result['min_change']:.2f}, {test_result['max_change']:.2f}] m\")\n",
    "else:\n",
    "    print(\"No glaciers found in this tile (expected for some tiles)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Execution Loop\n",
    "\n",
    "Process all DCM tiles and aggregate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_tiles(tif_files, glacier_gdf, verbose=True):\n",
    "    \"\"\"\n",
    "    Process all DCM tiles and aggregate glacier change statistics.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tif_files : list\n",
    "        List of paths to TIF files\n",
    "    glacier_gdf : GeoDataFrame\n",
    "        Glacier outlines\n",
    "    verbose : bool\n",
    "        Print progress information\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (results_df, all_pixel_values)\n",
    "        - results_df: DataFrame with per-tile statistics\n",
    "        - all_pixel_values: Concatenated array of all valid pixel values\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    all_values = []\n",
    "    tiles_with_glaciers = 0\n",
    "    \n",
    "    total_tiles = len(tif_files)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Processing {total_tiles} DCM tiles...\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    for i, tif_path in enumerate(sorted(tif_files), 1):\n",
    "        result = process_glacier_change(tif_path, glacier_gdf)\n",
    "        \n",
    "        if result is not None:\n",
    "            tiles_with_glaciers += 1\n",
    "            \n",
    "            # Store pixel values for histogram\n",
    "            all_values.append(result['all_values'])\n",
    "            \n",
    "            # Remove the large array from the results dict before storing\n",
    "            result_clean = {k: v for k, v in result.items() if k != 'all_values'}\n",
    "            results.append(result_clean)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"  [{i:2d}/{total_tiles}] {Path(tif_path).stem}: \"\n",
    "                      f\"{result['glaciers_in_tile']} glaciers, \"\n",
    "                      f\"mean \u0394h = {result['mean_change']:.2f} m\")\n",
    "        else:\n",
    "            if verbose and i % 10 == 0:\n",
    "                print(f\"  [{i:2d}/{total_tiles}] Processed (no glacier overlap)\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Complete! {tiles_with_glaciers}/{total_tiles} tiles contained glaciers.\")\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Concatenate all pixel values\n",
    "    all_pixel_values = np.concatenate(all_values) if all_values else np.array([])\n",
    "    \n",
    "    return results_df, all_pixel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all tiles\n",
    "results_df, all_pixel_values = process_all_tiles(tif_files, glaciers_gdf)\n",
    "\n",
    "print(f\"\\nTotal valid glacier pixels analyzed: {len(all_pixel_values):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display per-tile results\n",
    "print(\"\\nPer-Tile Results:\")\n",
    "print(\"=\"*80)\n",
    "results_df.sort_values('mean_change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate area-weighted (pixel-count weighted) regional statistics\n",
    "total_pixels = results_df['pixel_count'].sum()\n",
    "pixel_area_km2 = (PIXEL_RESOLUTION ** 2) / 1e6  # Convert m\u00b2 to km\u00b2\n",
    "\n",
    "# Weighted mean (accounts for different glacier coverage in each tile)\n",
    "weighted_mean_change = np.average(\n",
    "    results_df['mean_change'], \n",
    "    weights=results_df['pixel_count']\n",
    ")\n",
    "\n",
    "# Direct statistics from all pixel values\n",
    "overall_mean = np.mean(all_pixel_values)\n",
    "overall_median = np.median(all_pixel_values)\n",
    "overall_std = np.std(all_pixel_values)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REGIONAL SUMMARY: Sikkim, Bhutan, Arunachal Pradesh\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTiles processed: {len(results_df)}\")\n",
    "print(f\"Total glacier pixels: {total_pixels:,}\")\n",
    "print(f\"Equivalent glacier area analyzed: {total_pixels * pixel_area_km2:.2f} km\u00b2\")\n",
    "print(f\"\\n--- Elevation Change Statistics ---\")\n",
    "print(f\"Mean elevation change (\u0394h): {overall_mean:.2f} \u00b1 {overall_std:.2f} m\")\n",
    "print(f\"Median elevation change: {overall_median:.2f} m\")\n",
    "print(f\"Weighted mean (by pixel count): {weighted_mean_change:.2f} m\")\n",
    "print(f\"\\n--- Rate Estimates (over ~{TIME_PERIOD_YEARS} years) ---\")\n",
    "print(f\"Mean thinning rate: {overall_mean/TIME_PERIOD_YEARS:.3f} m/yr\")\n",
    "print(f\"Median thinning rate: {overall_median/TIME_PERIOD_YEARS:.3f} m/yr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Histogram of Elevation Changes\n",
    "This histogram shows the distribution of pixel values across all glaciers. A shift toward negative values indicates overall glacier thinning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# --- Left plot: Full histogram ---\n",
    "ax1 = axes[0]\n",
    "ax1.hist(all_pixel_values, bins=100, color='steelblue', edgecolor='none', alpha=0.7)\n",
    "ax1.axvline(x=0, color='black', linestyle='--', linewidth=1.5, label='Zero change')\n",
    "ax1.axvline(x=overall_mean, color='red', linestyle='-', linewidth=2, \n",
    "            label=f'Mean: {overall_mean:.2f} m')\n",
    "ax1.axvline(x=overall_median, color='orange', linestyle='-', linewidth=2,\n",
    "            label=f'Median: {overall_median:.2f} m')\n",
    "\n",
    "ax1.set_xlabel('Elevation Change (m)', fontsize=12)\n",
    "ax1.set_ylabel('Pixel Count', fontsize=12)\n",
    "ax1.set_title('Distribution of Glacier Surface Elevation Changes', fontsize=13)\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotation about negative shift\n",
    "negative_fraction = 100 * np.sum(all_pixel_values < 0) / len(all_pixel_values)\n",
    "ax1.text(0.98, 0.95, f'{negative_fraction:.1f}% of pixels\\nshow thinning',\n",
    "         transform=ax1.transAxes, fontsize=11, verticalalignment='top',\n",
    "         horizontalalignment='right', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# --- Right plot: Zoomed view (-30 to +20 m) ---\n",
    "ax2 = axes[1]\n",
    "zoomed_values = all_pixel_values[(all_pixel_values >= -30) & (all_pixel_values <= 20)]\n",
    "ax2.hist(zoomed_values, bins=80, color='steelblue', edgecolor='none', alpha=0.7)\n",
    "ax2.axvline(x=0, color='black', linestyle='--', linewidth=1.5, label='Zero change')\n",
    "ax2.axvline(x=overall_mean, color='red', linestyle='-', linewidth=2,\n",
    "            label=f'Mean: {overall_mean:.2f} m')\n",
    "ax2.axvline(x=overall_median, color='orange', linestyle='-', linewidth=2,\n",
    "            label=f'Median: {overall_median:.2f} m')\n",
    "\n",
    "ax2.set_xlabel('Elevation Change (m)', fontsize=12)\n",
    "ax2.set_ylabel('Pixel Count', fontsize=12)\n",
    "ax2.set_title('Zoomed View: -30m to +20m Range', fontsize=13)\n",
    "ax2.legend(loc='upper left')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'elevation_change_histogram.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Histogram saved to: {OUTPUT_DIR / 'elevation_change_histogram.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Per-Glacier Elevation Change Analysis\n",
    "Compute mean elevation change for each individual glacier polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_per_glacier_stats(tif_files, glacier_gdf,\n",
    "                              nodata=NODATA_VALUE,\n",
    "                              min_change=MIN_VALID_CHANGE,\n",
    "                              max_change=MAX_VALID_CHANGE):\n",
    "    \"\"\"\n",
    "    Compute elevation change statistics for each individual glacier.\n",
    "    \n",
    "    This function processes each glacier separately to enable per-glacier\n",
    "    mapping and analysis.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    GeoDataFrame : Input glaciers with added columns for change statistics\n",
    "    \"\"\"\n",
    "    # Initialize columns for results\n",
    "    glacier_gdf = glacier_gdf.copy()\n",
    "    glacier_gdf['mean_dh'] = np.nan\n",
    "    glacier_gdf['median_dh'] = np.nan\n",
    "    glacier_gdf['std_dh'] = np.nan\n",
    "    glacier_gdf['n_pixels'] = 0\n",
    "    glacier_gdf['dh_rate'] = np.nan  # m/yr\n",
    "    \n",
    "    print(f\"Computing per-glacier statistics for {len(glacier_gdf)} glaciers...\")\n",
    "    print(\"This may take several minutes...\")\n",
    "    \n",
    "    # Process each TIF file\n",
    "    for tif_idx, tif_path in enumerate(sorted(tif_files)):\n",
    "        try:\n",
    "            with rasterio.open(tif_path) as src:\n",
    "                raster_crs = src.crs\n",
    "                raster_bounds = src.bounds\n",
    "                raster_bbox = box(raster_bounds.left, raster_bounds.bottom,\n",
    "                                 raster_bounds.right, raster_bounds.top)\n",
    "                \n",
    "                # Reproject glaciers if needed\n",
    "                if glacier_gdf.crs != raster_crs:\n",
    "                    glaciers_reproj = glacier_gdf.to_crs(raster_crs)\n",
    "                else:\n",
    "                    glaciers_reproj = glacier_gdf\n",
    "                \n",
    "                # Find glaciers in this tile\n",
    "                intersects_mask = glaciers_reproj.intersects(raster_bbox)\n",
    "                \n",
    "                if not intersects_mask.any():\n",
    "                    continue\n",
    "                \n",
    "                # Process each glacier in this tile\n",
    "                for idx in glacier_gdf.index[intersects_mask]:\n",
    "                    try:\n",
    "                        geom = [mapping(glaciers_reproj.loc[idx, 'geometry'])]\n",
    "                        \n",
    "                        out_image, _ = mask(src, geom, crop=True, \n",
    "                                           all_touched=True, nodata=nodata)\n",
    "                        \n",
    "                        pixels = out_image[0].flatten()\n",
    "                        \n",
    "                        # Filter valid pixels\n",
    "                        valid = (pixels != nodata) & \\\n",
    "                                (pixels >= min_change) & \\\n",
    "                                (pixels <= max_change)\n",
    "                        \n",
    "                        valid_pixels = pixels[valid]\n",
    "                        \n",
    "                        if len(valid_pixels) > 0:\n",
    "                            # Accumulate statistics (handle glaciers spanning multiple tiles)\n",
    "                            prev_n = glacier_gdf.loc[idx, 'n_pixels']\n",
    "                            prev_mean = glacier_gdf.loc[idx, 'mean_dh']\n",
    "                            \n",
    "                            if prev_n > 0 and not np.isnan(prev_mean):\n",
    "                                # Weighted update for glaciers spanning tiles\n",
    "                                new_n = prev_n + len(valid_pixels)\n",
    "                                new_mean = (prev_mean * prev_n + np.sum(valid_pixels)) / new_n\n",
    "                                glacier_gdf.loc[idx, 'n_pixels'] = new_n\n",
    "                                glacier_gdf.loc[idx, 'mean_dh'] = new_mean\n",
    "                            else:\n",
    "                                glacier_gdf.loc[idx, 'mean_dh'] = np.mean(valid_pixels)\n",
    "                                glacier_gdf.loc[idx, 'median_dh'] = np.median(valid_pixels)\n",
    "                                glacier_gdf.loc[idx, 'std_dh'] = np.std(valid_pixels)\n",
    "                                glacier_gdf.loc[idx, 'n_pixels'] = len(valid_pixels)\n",
    "                                \n",
    "                    except Exception:\n",
    "                        continue\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Error processing {tif_path}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if (tif_idx + 1) % 10 == 0:\n",
    "            print(f\"  Processed {tif_idx + 1}/{len(tif_files)} tiles...\")\n",
    "    \n",
    "    # Calculate thinning rate\n",
    "    glacier_gdf['dh_rate'] = glacier_gdf['mean_dh'] / TIME_PERIOD_YEARS\n",
    "    \n",
    "    # Count glaciers with valid data\n",
    "    valid_glaciers = glacier_gdf['n_pixels'] > 0\n",
    "    print(f\"\\nComplete! {valid_glaciers.sum()}/{len(glacier_gdf)} glaciers have valid change data.\")\n",
    "    \n",
    "    return glacier_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute per-glacier statistics\n",
    "glaciers_with_stats = compute_per_glacier_stats(tif_files, glaciers_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to glaciers with valid data for visualization\n",
    "valid_glaciers = glaciers_with_stats[glaciers_with_stats['n_pixels'] > 0].copy()\n",
    "\n",
    "print(f\"Glaciers with valid elevation change data: {len(valid_glaciers)}\")\n",
    "print(f\"\\nPer-glacier statistics summary:\")\n",
    "print(f\"  Mean \u0394h: {valid_glaciers['mean_dh'].mean():.2f} \u00b1 {valid_glaciers['mean_dh'].std():.2f} m\")\n",
    "print(f\"  Median \u0394h: {valid_glaciers['mean_dh'].median():.2f} m\")\n",
    "print(f\"  Min \u0394h: {valid_glaciers['mean_dh'].min():.2f} m\")\n",
    "print(f\"  Max \u0394h: {valid_glaciers['mean_dh'].max():.2f} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Map of Glacier Thinning Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the map of glacier thinning\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "# Use a diverging colormap centered on zero\n",
    "# Blue = thickening (positive), Red = thinning (negative)\n",
    "vmin = valid_glaciers['mean_dh'].quantile(0.02)  # Clip outliers\n",
    "vmax = valid_glaciers['mean_dh'].quantile(0.98)\n",
    "\n",
    "# Center the colormap at zero\n",
    "norm = TwoSlopeNorm(vmin=vmin, vcenter=0, vmax=vmax)\n",
    "\n",
    "valid_glaciers.plot(\n",
    "    ax=ax,\n",
    "    column='mean_dh',\n",
    "    cmap='RdBu',  # Red (negative/thinning) to Blue (positive/thickening)\n",
    "    norm=norm,\n",
    "    legend=True,\n",
    "    legend_kwds={\n",
    "        'label': 'Mean Elevation Change (m)',\n",
    "        'shrink': 0.6,\n",
    "        'orientation': 'vertical'\n",
    "    },\n",
    "    edgecolor='face',\n",
    "    linewidth=0.1\n",
    ")\n",
    "\n",
    "# Add region labels\n",
    "ax.annotate('SIKKIM', xy=(88.5, 27.8), fontsize=14, fontweight='bold', \n",
    "            color='black', ha='center')\n",
    "ax.annotate('BHUTAN', xy=(89.8, 27.3), fontsize=14, fontweight='bold',\n",
    "            color='black', ha='center')\n",
    "ax.annotate('ARUNACHAL\\nPRADESH', xy=(93, 28.2), fontsize=14, fontweight='bold',\n",
    "            color='black', ha='center')\n",
    "\n",
    "ax.set_title('Glacier Surface Elevation Change: Sikkim, Bhutan, Arunachal Pradesh\\n'\n",
    "             '(TanDEM-X DEM Change Map Analysis)', fontsize=14)\n",
    "ax.set_xlabel('Longitude (\u00b0E)', fontsize=12)\n",
    "ax.set_ylabel('Latitude (\u00b0N)', fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add a text box with summary statistics\n",
    "textstr = f'Glaciers analyzed: {len(valid_glaciers)}\\n'\n",
    "textstr += f'Mean \u0394h: {valid_glaciers[\"mean_dh\"].mean():.2f} m\\n'\n",
    "textstr += f'Rate: {valid_glaciers[\"mean_dh\"].mean()/TIME_PERIOD_YEARS:.3f} m/yr'\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    "ax.text(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=11,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'glacier_thinning_map.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Map saved to: {OUTPUT_DIR / 'glacier_thinning_map.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Thinning Rate Distribution by Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify glaciers by approximate region based on longitude\n",
    "def classify_region(lon):\n",
    "    \"\"\"Classify glacier into region based on centroid longitude.\"\"\"\n",
    "    if lon < 89.0:\n",
    "        return 'Sikkim'\n",
    "    elif lon < 92.5:\n",
    "        return 'Bhutan'\n",
    "    else:\n",
    "        return 'Arunachal Pradesh'\n",
    "\n",
    "valid_glaciers['region'] = valid_glaciers['cenlon'].apply(classify_region)\n",
    "\n",
    "# Create box plot by region\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# --- Box plot ---\n",
    "ax1 = axes[0]\n",
    "regions = ['Sikkim', 'Bhutan', 'Arunachal Pradesh']\n",
    "data_by_region = [valid_glaciers[valid_glaciers['region'] == r]['mean_dh'] for r in regions]\n",
    "\n",
    "bp = ax1.boxplot(data_by_region, labels=regions, patch_artist=True)\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.6)\n",
    "\n",
    "ax1.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax1.set_ylabel('Mean Elevation Change (m)', fontsize=12)\n",
    "ax1.set_title('Elevation Change Distribution by Region', fontsize=13)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# --- Bar plot of mean values ---\n",
    "ax2 = axes[1]\n",
    "region_stats = valid_glaciers.groupby('region').agg({\n",
    "    'mean_dh': ['mean', 'std', 'count']\n",
    "}).reset_index()\n",
    "region_stats.columns = ['region', 'mean', 'std', 'count']\n",
    "region_stats = region_stats.set_index('region').loc[regions].reset_index()\n",
    "\n",
    "bars = ax2.bar(region_stats['region'], region_stats['mean'], \n",
    "               yerr=region_stats['std']/np.sqrt(region_stats['count']),  # Standard error\n",
    "               capsize=5, color=colors, alpha=0.7, edgecolor='black')\n",
    "\n",
    "ax2.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax2.set_ylabel('Mean Elevation Change (m)', fontsize=12)\n",
    "ax2.set_title('Mean Elevation Change by Region (\u00b1SE)', fontsize=13)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add count labels\n",
    "for bar, count in zip(bars, region_stats['count']):\n",
    "    height = bar.get_height()\n",
    "    ax2.annotate(f'n={count}',\n",
    "                xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, -20),\n",
    "                textcoords='offset points',\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'regional_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Regional comparison saved to: {OUTPUT_DIR / 'regional_comparison.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Results & Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table by region\n",
    "print(\"=\"*80)\n",
    "print(\"SUMMARY TABLE: Glacier Surface Elevation Change\")\n",
    "print(\"Region: Sikkim, Bhutan, Arunachal Pradesh (Eastern Himalaya)\")\n",
    "print(\"Data: TanDEM-X DEM Change Map (DCM)\")\n",
    "print(f\"Time Period: ~{TIME_PERIOD_YEARS} years (TanDEM-X baseline to recent)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "for region in ['Sikkim', 'Bhutan', 'Arunachal Pradesh']:\n",
    "    region_data = valid_glaciers[valid_glaciers['region'] == region]\n",
    "    \n",
    "    if len(region_data) > 0:\n",
    "        summary_data.append({\n",
    "            'Region': region,\n",
    "            'Glaciers': len(region_data),\n",
    "            'Total Area (km\u00b2)': region_data['area_km2'].sum(),\n",
    "            'Mean \u0394h (m)': region_data['mean_dh'].mean(),\n",
    "            'Std \u0394h (m)': region_data['mean_dh'].std(),\n",
    "            'Median \u0394h (m)': region_data['mean_dh'].median(),\n",
    "            'Rate (m/yr)': region_data['mean_dh'].mean() / TIME_PERIOD_YEARS\n",
    "        })\n",
    "\n",
    "# Add total row\n",
    "summary_data.append({\n",
    "    'Region': 'TOTAL/OVERALL',\n",
    "    'Glaciers': len(valid_glaciers),\n",
    "    'Total Area (km\u00b2)': valid_glaciers['area_km2'].sum(),\n",
    "    'Mean \u0394h (m)': valid_glaciers['mean_dh'].mean(),\n",
    "    'Std \u0394h (m)': valid_glaciers['mean_dh'].std(),\n",
    "    'Median \u0394h (m)': valid_glaciers['mean_dh'].median(),\n",
    "    'Rate (m/yr)': valid_glaciers['mean_dh'].mean() / TIME_PERIOD_YEARS\n",
    "})\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Format the table\n",
    "print(\"\\n\")\n",
    "print(summary_df.to_string(index=False, \n",
    "                           formatters={\n",
    "                               'Total Area (km\u00b2)': '{:.1f}'.format,\n",
    "                               'Mean \u0394h (m)': '{:.2f}'.format,\n",
    "                               'Std \u0394h (m)': '{:.2f}'.format,\n",
    "                               'Median \u0394h (m)': '{:.2f}'.format,\n",
    "                               'Rate (m/yr)': '{:.3f}'.format\n",
    "                           }))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate total volume change\n",
    "pixel_area_m2 = PIXEL_RESOLUTION ** 2  # 900 m\u00b2\n",
    "\n",
    "# Using the pixel-level data for more accurate volume estimation\n",
    "total_volume_change_m3 = np.sum(all_pixel_values) * pixel_area_m2\n",
    "total_volume_change_km3 = total_volume_change_m3 / 1e9\n",
    "\n",
    "# Equivalent water loss (ice density ~900 kg/m\u00b3)\n",
    "ice_density = 900  # kg/m\u00b3\n",
    "water_density = 1000  # kg/m\u00b3\n",
    "water_equivalent_km3 = total_volume_change_km3 * (ice_density / water_density)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VOLUME CHANGE ESTIMATES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal glacier pixels analyzed: {len(all_pixel_values):,}\")\n",
    "print(f\"Total area analyzed: {len(all_pixel_values) * pixel_area_m2 / 1e6:.2f} km\u00b2\")\n",
    "print(f\"\\nTotal volume change: {total_volume_change_km3:.3f} km\u00b3\")\n",
    "print(f\"Water equivalent: {water_equivalent_km3:.3f} km\u00b3\")\n",
    "print(f\"\\nAnnual rate: {total_volume_change_km3/TIME_PERIOD_YEARS:.4f} km\u00b3/yr\")\n",
    "print(f\"Annual water equivalent: {water_equivalent_km3/TIME_PERIOD_YEARS:.4f} km\u00b3/yr\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"INTERPRETATION NOTES:\")\n",
    "print(\"-\"*60)\n",
    "print(\"\"\"\n",
    "\u2022 Negative values indicate surface lowering (glacier thinning/mass loss)\n",
    "\u2022 The TanDEM-X DCM captures surface elevation change, not direct mass change\n",
    "\u2022 Radar penetration into snow/firn can affect measurements in accumulation zones\n",
    "\u2022 Values filtered to remove obvious noise (> +100m or < -150m)\n",
    "\u2022 Time period is approximate based on TanDEM-X acquisition dates\n",
    "\u2022 For accurate mass balance, density assumptions are required\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "summary_df.to_csv(OUTPUT_DIR / 'regional_summary.csv', index=False)\n",
    "print(f\"Summary table saved to: {OUTPUT_DIR / 'regional_summary.csv'}\")\n",
    "\n",
    "# Save per-glacier results\n",
    "export_cols = ['rgi_id', 'glac_name', 'cenlon', 'cenlat', 'area_km2', \n",
    "               'mean_dh', 'median_dh', 'std_dh', 'n_pixels', 'dh_rate', 'region']\n",
    "export_cols = [c for c in export_cols if c in valid_glaciers.columns]\n",
    "\n",
    "valid_glaciers[export_cols].to_csv(OUTPUT_DIR / 'per_glacier_results.csv', index=False)\n",
    "print(f\"Per-glacier results saved to: {OUTPUT_DIR / 'per_glacier_results.csv'}\")\n",
    "\n",
    "# Save the GeoDataFrame with results as a new shapefile\n",
    "valid_glaciers.to_file(OUTPUT_DIR / 'glaciers_with_change.shp')\n",
    "print(f\"Shapefile with results saved to: {OUTPUT_DIR / 'glaciers_with_change.shp'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Additional Analysis: Elevation Dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if elevation data is available in the RGI shapefile\n",
    "elev_cols = [c for c in valid_glaciers.columns if 'elev' in c.lower() or 'zmed' in c.lower()]\n",
    "print(f\"Available elevation columns: {elev_cols}\")\n",
    "\n",
    "if 'zmed' in valid_glaciers.columns or 'zmed_m' in valid_glaciers.columns:\n",
    "    elev_col = 'zmed' if 'zmed' in valid_glaciers.columns else 'zmed_m'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Scatter plot of elevation change vs median elevation\n",
    "    scatter = ax.scatter(\n",
    "        valid_glaciers[elev_col],\n",
    "        valid_glaciers['mean_dh'],\n",
    "        c=valid_glaciers['area_km2'],\n",
    "        cmap='viridis',\n",
    "        alpha=0.6,\n",
    "        s=20\n",
    "    )\n",
    "    \n",
    "    ax.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    ax.set_xlabel('Median Glacier Elevation (m a.s.l.)', fontsize=12)\n",
    "    ax.set_ylabel('Mean Elevation Change (m)', fontsize=12)\n",
    "    ax.set_title('Elevation Change vs. Glacier Altitude', fontsize=13)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    cbar = plt.colorbar(scatter, ax=ax, shrink=0.8)\n",
    "    cbar.set_label('Glacier Area (km\u00b2)', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'elevation_dependence.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Elevation dependence plot saved to: {OUTPUT_DIR / 'elevation_dependence.png'}\")\n",
    "else:\n",
    "    print(\"Median elevation data not available in shapefile.\")\n",
    "    print(\"Skipping elevation dependence analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "This analysis processed TanDEM-X DEM Change Maps (DCM) to estimate glacier surface elevation changes in the Sikkim, Bhutan, and Arunachal Pradesh regions of the Eastern Himalaya.\n",
    "\n",
    "### Key Outputs:\n",
    "1. **Regional Statistics**: Mean, median, and standard deviation of elevation change by region\n",
    "2. **Per-Glacier Data**: Individual glacier statistics saved as CSV and Shapefile\n",
    "3. **Visualizations**: \n",
    "   - Histogram of pixel-level elevation changes\n",
    "   - Map of per-glacier thinning rates\n",
    "   - Regional comparison plots\n",
    "\n",
    "### Limitations:\n",
    "- Time period is approximate (based on TanDEM-X naming conventions)\n",
    "- Radar penetration effects not corrected\n",
    "- Void pixels and data gaps may affect some glaciers\n",
    "- Volume-to-mass conversion requires density assumptions\n",
    "\n",
    "### Next Steps:\n",
    "- Compare with independent datasets (ICESat-2, ASTER)\n",
    "- Apply glacier-specific penetration corrections\n",
    "- Analyze temporal trends if multi-epoch data available"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
